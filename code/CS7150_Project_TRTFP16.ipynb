{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOojRybctPMaZWLXLoHFB38"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["TRT FP16"],"metadata":{"id":"SBCluoy-NSqp"}},{"cell_type":"code","source":["!pip install torch_tensorrt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lhr0PMrNWZnl","executionInfo":{"status":"ok","timestamp":1745270436338,"user_tz":240,"elapsed":285556,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}},"outputId":"5fa393ac-9133-466b-e03e-674e57c4d7cf"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_tensorrt\n","  Downloading torch_tensorrt-2.6.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torch_tensorrt) (2.6.0+cu124)\n","Collecting tensorrt<10.8.0,>=10.7.0.post1 (from torch_tensorrt)\n","  Downloading tensorrt-10.7.0.post1.tar.gz (35 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorrt-cu12<10.8.0,>=10.7.0.post1 (from torch_tensorrt)\n","  Downloading tensorrt_cu12-10.7.0.post1.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorrt-cu12-bindings<10.8.0,>=10.7.0 (from torch_tensorrt)\n","  Downloading tensorrt_cu12_bindings-10.7.0.post1-cp311-none-manylinux_2_17_x86_64.whl.metadata (628 bytes)\n","Collecting tensorrt-cu12-libs<10.8.0,>=10.7.0 (from torch_tensorrt)\n","  Downloading tensorrt_cu12_libs-10.7.0.post1.tar.gz (710 bytes)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.11/dist-packages (from torch_tensorrt) (24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_tensorrt) (2.0.2)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from torch_tensorrt) (4.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torch_tensorrt)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch_tensorrt) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torch_tensorrt) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torch_tensorrt) (3.0.2)\n","Downloading torch_tensorrt-2.6.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl (3.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorrt_cu12_bindings-10.7.0.post1-cp311-none-manylinux_2_17_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt-cu12, tensorrt-cu12-libs\n","  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt: filename=tensorrt-10.7.0.post1-py2.py3-none-any.whl size=42170 sha256=918d39c54ea184c25a201e13254f44d5bac7ede9a045e3e05b5cd3208e800d23\n","  Stored in directory: /root/.cache/pip/wheels/56/f9/fa/d8dc822675c08f0b9f87bb4f080164bb4cf206692e2e62c0ae\n","  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.7.0.post1-py2.py3-none-any.whl size=17632 sha256=ff5f2ab4f13c56747ce92d8138cf5115d0d044656e29facd216abdd04fdd3aef\n","  Stored in directory: /root/.cache/pip/wheels/31/95/0d/93bc3231ac7802cf65d5600a1848f0052c3b34bf77a8138c28\n","  Building wheel for tensorrt-cu12-libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.7.0.post1-py2.py3-none-manylinux_2_17_x86_64.whl size=2069981220 sha256=ab4b8ef46a113f2e704b4c755c4db89789d70069c806d50683e17811060a09e2\n","  Stored in directory: /root/.cache/pip/wheels/7f/37/a3/80b753dffe437ee9003d15cefa3dfb451ade6e484737f97379\n","Successfully built tensorrt tensorrt-cu12 tensorrt-cu12-libs\n","Installing collected packages: tensorrt-cu12-bindings, tensorrt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tensorrt-cu12-libs, tensorrt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch_tensorrt\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensorrt-10.7.0.post1 tensorrt-cu12-10.7.0.post1 tensorrt-cu12-bindings-10.7.0.post1 tensorrt-cu12-libs-10.7.0.post1 torch_tensorrt-2.6.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"EM2acPy7_GWQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745270457029,"user_tz":240,"elapsed":20672,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}},"outputId":"8e7fec04-0aed-46d0-e7e0-9c09a6b1b20d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ResNet Model Evaluation on ImageNet Test Set Sample with TensorRT FP16 Quantization\n","\n","import torch\n","import torch_tensorrt\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import random\n","import os\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","\n","# Print TensorRT version for debugging\n","print(f\"Torch-TensorRT version: {torch_tensorrt.__version__}\")\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"CUDA version: {torch.version.cuda}\")\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Define the transformation pipeline for the validation set\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","imagenet_path = \"/content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/\"\n","print(f\"Loading from: {imagenet_path}\")\n","\n","# Get all class folders\n","class_folders = [d for d in os.listdir(imagenet_path)\n","                 if os.path.isdir(os.path.join(imagenet_path, d))]\n","all_image_files = []\n","\n","# Collect all jpg files\n","for folder in class_folders:\n","    folder_path = os.path.join(imagenet_path, folder)\n","    files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.jpg')]\n","    all_image_files.extend(files)\n","\n","print(f\"Found a total of {len(all_image_files)} images\")\n","\n","# Randomly sample 50 images\n","num_samples = 50\n","if len(all_image_files) > num_samples:\n","    random.shuffle(all_image_files)\n","    sampled_images = all_image_files[:num_samples]\n","else:\n","    sampled_images = all_image_files\n","\n","print(f\"Randomly sampled {len(sampled_images)} images for testing\")\n","\n","# Create a simple mapping from folder name to class index\n","folder_to_idx = {folder: idx for idx, folder in enumerate(sorted(class_folders))}\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QSRB3o8_ul8","executionInfo":{"status":"ok","timestamp":1745270537230,"user_tz":240,"elapsed":40167,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}},"outputId":"0c0b1c3e-1c3a-4e4b-b794-3f2a1655a42c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:torch_tensorrt.dynamo.conversion.aten_ops_converters:Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models\n","WARNING:torch_tensorrt.dynamo.conversion.converter_utils:TensorRT-LLM is not installed. Please install TensorRT-LLM or set TRTLLM_PLUGINS_PATH to the directory containing libnvinfer_plugin_tensorrt_llm.so to use converters for torch.distributed ops\n"]},{"output_type":"stream","name":"stdout","text":["Torch-TensorRT version: 2.6.0\n","PyTorch version: 2.6.0+cu124\n","CUDA available: True\n","CUDA version: 12.4\n","Using device: cuda:0\n","Loading from: /content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/\n","Found a total of 5450 images\n","Randomly sampled 50 images for testing\n"]}]},{"cell_type":"code","source":["# Custom dataset for the sampled images\n","class SampledImageNetDataset(Dataset):\n","    def __init__(self, image_files, transform=None):\n","        self.image_files = image_files\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_files[idx]\n","\n","        # Get the class folder from the path\n","        folder_name = os.path.basename(os.path.dirname(img_path))\n","        class_idx = folder_to_idx[folder_name]\n","\n","        # Load and transform the image\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, class_idx\n","\n","# Create the dataset and dataloader\n","sample_dataset = SampledImageNetDataset(sampled_images, transform=preprocess)\n","sample_loader = DataLoader(sample_dataset, batch_size=1, shuffle=False)\n","\n","print(f\"Created dataset with {len(sample_dataset)} images\")\n","print(f\"Number of classes represented: {len(set(folder_to_idx.values()))}\")\n","\n","# Create class mapping for visualization\n","idx_to_class = {v: k for k, v in folder_to_idx.items()}\n","\n","# Print a few examples\n","print(\"\\nSample images:\")\n","for i in range(min(5, len(sampled_images))):\n","    img_path = sampled_images[i]\n","    folder = os.path.basename(os.path.dirname(img_path))\n","    print(f\"{i+1}. {img_path} (Class: {folder})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWYFLY0AOU9I","executionInfo":{"status":"ok","timestamp":1745270537236,"user_tz":240,"elapsed":12,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}},"outputId":"e2602ef6-ea56-438c-a818-d06d46ee88b4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Created dataset with 50 images\n","Number of classes represented: 109\n","\n","Sample images:\n","1. /content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/00030/398679180989368.jpg (Class: 00030)\n","2. /content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/00092/7475549699225013.jpg (Class: 00092)\n","3. /content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/00048/954069468668238.jpg (Class: 00048)\n","4. /content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/00033/5350927420497062.jpg (Class: 00033)\n","5. /content/drive/My Drive/assignments_dl_cs7150/project/imagenet_data/dataset_dl/00069/589123649299837.jpg (Class: 00069)\n"]}]},{"cell_type":"code","source":["# Function to evaluate model on the test set\n","def evaluate_model(model, data_loader, num_runs=5):\n","    model.eval()\n","\n","    all_top1 = []\n","    all_top5 = []\n","\n","    for run in range(num_runs):\n","        print(f\"Accuracy evaluation - Run {run+1}/{num_runs}\")\n","\n","        # For top-1 and top-5 accuracy\n","        top1_correct = 0\n","        top5_correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for images, labels in data_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","\n","                # Top-1 accuracy\n","                _, predicted = torch.max(outputs, 1)\n","                top1_correct += (predicted == labels).sum().item()\n","\n","                # Top-5 accuracy\n","                _, top5_preds = torch.topk(outputs, 5, dim=1)\n","                for i in range(labels.size(0)):\n","                    if labels[i] in top5_preds[i]:\n","                        top5_correct += 1\n","\n","                total += labels.size(0)\n","\n","        top1_accuracy = 100 * top1_correct / total\n","        top5_accuracy = 100 * top5_correct / total\n","\n","        all_top1.append(top1_accuracy)\n","        all_top5.append(top5_accuracy)\n","\n","        print(f\"  Run {run+1} - Top-1: {top1_accuracy:.2f}%, Top-5: {top5_accuracy:.2f}%\")\n","\n","    # Calculate average and standard deviation\n","    avg_top1 = np.mean(all_top1)\n","    std_top1 = np.std(all_top1)\n","    avg_top5 = np.mean(all_top5)\n","    std_top5 = np.std(all_top5)\n","\n","    print(f\"Average Top-1: {avg_top1:.2f}% ± {std_top1:.2f}%\")\n","    print(f\"Average Top-5: {avg_top5:.2f}% ± {std_top5:.2f}%\")\n","\n","    return avg_top1, std_top1, avg_top5, std_top5"],"metadata":{"id":"UYPXZQ4ENxm8","executionInfo":{"status":"ok","timestamp":1745270537261,"user_tz":240,"elapsed":22,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def measure_fps(model, input_tensor, num_runs=20):\n","    \"\"\"Measure FPS with improved statistical robustness.\"\"\"\n","    input_tensor = input_tensor.to(device)\n","    model.eval()\n","\n","    all_fps = []\n","\n","    # More warm-up runs\n","    with torch.no_grad():\n","        for _ in range(10):  # Increased from 5 to 10\n","            model(input_tensor)\n","\n","    for run in range(num_runs):\n","        print(f\"FPS measurement - Run {run+1}/{num_runs}\")\n","\n","        # Actual timing\n","        start_time = time.time()\n","        test_iterations = 50  # Increased from 20 to 50 for more stability\n","        with torch.no_grad():\n","            for _ in range(test_iterations):\n","                model(input_tensor)\n","\n","        end_time = time.time()\n","        time_per_image = (end_time - start_time) / test_iterations\n","        fps = 1.0 / time_per_image\n","        all_fps.append(fps)\n","\n","        print(f\"  Run {run+1} FPS: {fps:.2f}\")\n","\n","    # Calculate statistics\n","    all_fps = np.array(all_fps)\n","\n","    # Outlier detection (remove values beyond 2 standard deviations)\n","    mean = np.mean(all_fps)\n","    std = np.std(all_fps)\n","    filtered_fps = all_fps[np.abs(all_fps - mean) <= 2 * std]\n","\n","    # If too many points are removed, revert to using all points\n","    if len(filtered_fps) < 0.7 * len(all_fps):\n","        filtered_fps = all_fps\n","        print(\"Outlier filtering skipped (too many potential outliers)\")\n","    else:\n","        print(f\"Removed {len(all_fps) - len(filtered_fps)} outliers\")\n","\n","    # Calculate mean, median and their respective dispersion metrics\n","    mean_fps = np.mean(filtered_fps)\n","    std_fps = np.std(filtered_fps)\n","\n","    # Calculate median and median absolute deviation (more robust)\n","    median_fps = np.median(filtered_fps)\n","    mad_fps = np.median(np.abs(filtered_fps - median_fps)) * 1.4826  # Factor to make MAD comparable to std dev\n","\n","    cv = (std_fps / mean_fps) * 100  # Coefficient of variation\n","\n","    print(f\"Mean FPS: {mean_fps:.2f} ± {std_fps:.2f} (CV: {cv:.2f}%)\")\n","    print(f\"Median FPS: {median_fps:.2f} ± {mad_fps:.2f}\")\n","    return median_fps\n","\n","\n","# Show a few sample images with predictions\n","def visualize_predictions(model_obj, dataset, loader, num_samples=5):\n","    model_obj.eval()\n","    fig, axes = plt.subplots(1, num_samples, figsize=(20, 4))\n","\n","    with torch.no_grad():\n","        for i, (images, labels) in enumerate(loader):\n","            if i >= num_samples:\n","                break\n","\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model_obj(images)\n","\n","            # Get predicted class\n","            _, predicted = torch.max(outputs, 1)\n","\n","            # Get class names (folder names)\n","            true_class_idx = labels.item()\n","            pred_class_idx = predicted.item()\n","\n","            true_class = idx_to_class[true_class_idx]\n","            pred_class = idx_to_class.get(pred_class_idx, f\"Unknown ({pred_class_idx})\")\n","\n","            # Get image\n","            img = images[0].cpu().numpy().transpose((1, 2, 0))\n","            # Denormalize\n","            img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","            img = np.clip(img, 0, 1)\n","\n","            # Plot\n","            axes[i].imshow(img)\n","            axes[i].set_title(f\"True: {true_class}\\nPred: {pred_class}\")\n","            axes[i].axis('off')\n","\n","    plt.tight_layout()\n","    plt.savefig('sample_predictions_tensorrt_fp16.png')\n","    plt.show()\n","\n","\n","\n","# Function to count parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"metadata":{"id":"ZPrxelItNtzh","executionInfo":{"status":"ok","timestamp":1745270853019,"user_tz":240,"elapsed":65,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Function to calculate model size in MB for PyTorch models\n","def calculate_pytorch_model_size(model):\n","    # Get model state_dict\n","    state_dict = model.state_dict()\n","\n","    # Calculate total size in bytes\n","    total_size = 0\n","    for param in state_dict.values():\n","        # Calculate bytes for each parameter\n","        total_size += param.numel() * param.element_size()\n","\n","    # Convert to MB\n","    size_mb = total_size / (1024 * 1024)\n","\n","    return size_mb\n","\n","# Function to calculate TensorRT model size based on parameter count and precision\n","def calculate_tensorrt_model_size(param_count, precision='fp16'):\n","    # Determine bytes per parameter based on precision\n","    if precision.lower() == 'fp16':\n","        bytes_per_param = 2  # 16 bits = 2 bytes\n","    elif precision.lower() == 'fp32':\n","        bytes_per_param = 4  # 32 bits = 4 bytes\n","    elif precision.lower() == 'int8':\n","        bytes_per_param = 1  # 8 bits = 1 byte\n","    else:\n","        bytes_per_param = 4  # Default to FP32\n","\n","    # Calculate total size in MB\n","    size_mb = (param_count * bytes_per_param) / (1024 * 1024)\n","\n","    return size_mb"],"metadata":{"id":"4zHYLUtdO11t","executionInfo":{"status":"ok","timestamp":1745270854701,"user_tz":240,"elapsed":2,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create FP16 TensorRT engine\n","def create_fp16_trt_engine():\n","    print(\"Loading base ResNet18 model...\")\n","    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","    model = model.to(device)\n","    model.eval()\n","\n","    print(\"Tracing model...\")\n","    example_input = torch.randn(1, 3, 224, 224).to(device)\n","    traced_model = torch.jit.trace(model, example_input)\n","    traced_model = torch.jit.freeze(traced_model)\n","\n","    print(\"Setting up FP16 TensorRT compilation...\")\n","\n","    input_specs = [torch_tensorrt.Input(\n","        min_shape=[1, 3, 224, 224],\n","        opt_shape=[1, 3, 224, 224],\n","        max_shape=[1, 3, 224, 224],\n","        dtype=torch.float32\n","    )]\n","\n","    trt_model = torch_tensorrt.compile(\n","        traced_model,\n","        inputs=input_specs,\n","        enabled_precisions={torch.float16},  # Use FP16 precision\n","        workspace_size=1 << 22,  # 4MB workspace\n","        truncate_long_and_double=True\n","    )\n","    print(\"Successfully compiled with FP16 precision\")\n","    return trt_model\n","\n","# Store results\n","results = {\n","    'model': [],\n","    'top1_accuracy': [],\n","    'top1_std': [],\n","    'top5_accuracy': [],\n","    'top5_std': [],\n","    'parameters': [],\n","    'model_size': [],     # Added for model size in MB\n","    'fps': [],\n","    'fps_std': []\n","}\n","\n","# Number of runs for each evaluation\n","NUM_RUNS = 5\n","print(f\"Evaluating each model with {NUM_RUNS} runs for averaging\")\n","\n","# Create dummy input for FPS measurement\n","dummy_input = torch.randn(1, 3, 224, 224).to(device)\n","\n","# Evaluate original PyTorch ResNet-18\n","print(\"\\nEvaluating original PyTorch ResNet-18...\")\n","resnet18_original = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(device).eval()\n","num_params_original = count_parameters(resnet18_original)\n","model_size_original = calculate_pytorch_model_size(resnet18_original)\n","\n","# Run multiple times and average\n","fps_original = measure_fps(resnet18_original, dummy_input, num_runs=NUM_RUNS)\n","top1_acc_original, top1_std_original, top5_acc_original, top5_std_original = evaluate_model(resnet18_original, sample_loader, num_runs=NUM_RUNS)\n","\n","print(f\"Number of parameters: {num_params_original:,}\")\n","print(f\"Model size: {model_size_original:.2f} MB\")\n","print(f\"FPS: {fps_original:.2f}\")\n","print(f\"Top-1 accuracy: {top1_acc_original:.2f}% ± {top1_std_original:.2f}%\")\n","print(f\"Top-5 accuracy: {top5_acc_original:.2f}% ± {top5_std_original:.2f}%\")\n","\n","results['model'].append('ResNet18\\nPyTorch')\n","results['top1_accuracy'].append(top1_acc_original)\n","results['top1_std'].append(top1_std_original)\n","results['top5_accuracy'].append(top5_acc_original)\n","results['top5_std'].append(top5_std_original)\n","results['parameters'].append(num_params_original)\n","results['model_size'].append(model_size_original)\n","results['fps'].append(fps_original)\n","\n","\n","# Evaluate TensorRT FP16 model\n","print(\"\\nEvaluating ResNet-18 with TensorRT FP16...\")\n","resnet18_trt_fp16 = create_fp16_trt_engine()\n","num_params_trt_fp16 = num_params_original  # Parameters count should be the same\n","\n","# For TensorRT models, calculate size based on parameter count and precision\n","model_size_trt_fp16 = calculate_tensorrt_model_size(num_params_trt_fp16, precision='fp16')\n","print(f\"TensorRT FP16 model size (based on parameter count): {model_size_trt_fp16:.2f} MB\")\n","\n","# Run multiple times and average\n","fps_trt_fp16 = measure_fps(resnet18_trt_fp16, dummy_input, num_runs=NUM_RUNS)\n","top1_acc_trt_fp16, top1_std_trt_fp16, top5_acc_trt_fp16, top5_std_trt_fp16 = evaluate_model(resnet18_trt_fp16, sample_loader, num_runs=NUM_RUNS)\n","\n","print(f\"Number of parameters: {num_params_trt_fp16:,}\")\n","print(f\"Model size: {model_size_trt_fp16:.2f} MB\")\n","# print(f\"FPS: {fps_trt_fp16:.2f} ± {fps_trt_fp16_std:.2f}\")\n","print(f\"Top-1 accuracy: {top1_acc_trt_fp16:.2f}% ± {top1_std_trt_fp16:.2f}%\")\n","print(f\"Top-5 accuracy: {top5_acc_trt_fp16:.2f}% ± {top5_std_trt_fp16:.2f}%\")\n","\n","results['model'].append('ResNet18\\nTRT FP16')\n","results['top1_accuracy'].append(top1_acc_trt_fp16)\n","results['top1_std'].append(top1_std_trt_fp16)\n","results['top5_accuracy'].append(top5_acc_trt_fp16)\n","results['top5_std'].append(top5_std_trt_fp16)\n","results['parameters'].append(num_params_trt_fp16)\n","results['model_size'].append(model_size_trt_fp16)\n","results['fps'].append(fps_trt_fp16)\n","# results['fps_std'].append(fps_trt_fp16_std)\n","\n","# Plot the results with error bars\n","fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # Changed to 1 row, 3 columns\n","\n","# Accuracy plot (combining top-1 and top-5 with error bars)\n","bar_width = 0.35\n","x = np.arange(len(results['model']))\n","axs[0].bar(x - bar_width/2, results['top1_accuracy'], bar_width, color='skyblue', label='Top-1')\n","axs[0].bar(x + bar_width/2, results['top5_accuracy'], bar_width, color='lightgreen', label='Top-5')\n","\n","# Add error bars\n","axs[0].errorbar(x - bar_width/2, results['top1_accuracy'], yerr=results['top1_std'],\n","              fmt='none', ecolor='black', capsize=5)\n","axs[0].errorbar(x + bar_width/2, results['top5_accuracy'], yerr=results['top5_std'],\n","              fmt='none', ecolor='black', capsize=5)\n","\n","axs[0].set_xlabel('Model')\n","axs[0].set_ylabel('Accuracy (%)')\n","axs[0].set_title(f'Test Accuracy (Average of {NUM_RUNS} runs)')\n","axs[0].set_xticks(x)\n","axs[0].set_xticklabels(results['model'])\n","axs[0].set_ylim([60, 100])  # Adjusted to zoom in on relevant accuracy range\n","axs[0].legend()\n","for i, v in enumerate(results['top1_accuracy']):\n","    axs[0].text(i - bar_width/2, v + 2, f\"{v:.2f}%\", ha='center', fontsize=9)\n","for i, v in enumerate(results['top5_accuracy']):\n","    axs[0].text(i + bar_width/2, v + 2, f\"{v:.2f}%\", ha='center', fontsize=9)\n","\n","# FPS plot with error bars\n","axs[1].bar(x, results['fps'], color='gold')\n","axs[1].errorbar(x, results['fps'],\n","              fmt='none', ecolor='black', capsize=5)\n","axs[1].set_xlabel('Model')\n","axs[1].set_ylabel('FPS')\n","axs[1].set_title(f'Frames Per Second (Average of {NUM_RUNS} runs)')\n","axs[1].set_xticks(x)\n","axs[1].set_xticklabels(results['model'])\n","for i, v in enumerate(results['fps']):\n","    axs[1].text(i, v + 0.5, f\"{v:.2f}\", ha='center', fontsize=9)\n","\n","# Model Size plot\n","axs[2].bar(x, results['model_size'], color='lightcoral')\n","axs[2].set_xlabel('Model')\n","axs[2].set_ylabel('Model Size (MB)')\n","axs[2].set_title('Model Size Comparison')\n","axs[2].set_xticks(x)\n","axs[2].set_xticklabels(results['model'])\n","for i, v in enumerate(results['model_size']):\n","    axs[2].text(i, v + 0.5, f\"{v:.2f} MB\", ha='center')\n","\n","plt.tight_layout()\n","plt.savefig('resnet18_tensorrt_fp16_comparison_avg5runs.png', dpi=300)\n","plt.show()\n","# params_in_millions = []\n","params_in_millions = [p / 1_000_000 for p in results['parameters']]\n","# Create a table with all the results\n","try:\n","    from prettytable import PrettyTable\n","    table = PrettyTable()\n","    table.field_names = [\"Model\", \"Top-1 Acc (%)\", \"Top-5 Acc (%)\", \"Parameters (M)\", \"FPS\"]\n","\n","    for i, model in enumerate(results['model']):\n","        table.add_row([\n","            model,\n","            f\"{results['top1_accuracy'][i]:.2f} ± {results['top1_std'][i]:.2f}\",\n","            f\"{results['top5_accuracy'][i]:.2f} ± {results['top5_std'][i]:.2f}\",\n","            f\"{params_in_millions[i]:.2f}\",\n","            f\"{results['fps'][i]:.2f}\"\n","        ])\n","\n","    print(\"\\nPerformance Comparison (Averaged over 5 runs):\")\n","    print(table)\n","except ImportError:\n","    print(\"\\nPerformance Comparison (Averaged over 5 runs):\")\n","    for i, model in enumerate(results['model']):\n","        print(f\"{model}: Top-1={results['top1_accuracy'][i]:.2f}% ± {results['top1_std'][i]:.2f}, \"\n","              f\"Top-5={results['top5_accuracy'][i]:.2f}% ± {results['top5_std'][i]:.2f}, \"\n","              f\"Params={params_in_millions[i]:.2f}M, \"\n","              f\"FPS={results['fps'][i]:.2f}\")\n","\n","# Visualize using TensorRT FP16 model\n","print(\"\\nVisualizing sample predictions using TensorRT FP16 ResNet-18:\")\n","visualize_predictions(resnet18_trt_fp16, sample_dataset, sample_loader)\n","\n","# Visualize the original model for comparison\n","print(\"\\nVisualizing sample predictions using original ResNet-18 for comparison:\")\n","visualize_predictions(resnet18_original, sample_dataset, sample_loader)\n","\n","print(\"\\nEvaluation complete!\")\n","print(f\"Results are saved as 'resnet18_tensorrt_fp16_comparison_avg5runs.png' and 'sample_predictions_tensorrt_fp16.png'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Af0-ljgUnOR0yehF5KgXDFo1bhWUdAFT"},"id":"hYtBMXYaNnwq","executionInfo":{"status":"ok","timestamp":1745271609675,"user_tz":240,"elapsed":31394,"user":{"displayName":"Poornima JD","userId":"00315572794735409627"}},"outputId":"dcda9ca1-010e-47cf-d704-ece19a8cc3c7"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}